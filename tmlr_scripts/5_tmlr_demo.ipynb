{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Measure of the Complexity of Neural Representations based on Partial Information Decomposition\n",
    "David A. Ehrlich, Andreas C. Schneider, Viola Priesemann, Michael Wibral, Abdullah Makkeh. TMLR 2023.\\\n",
    "Supplementary Code -  Script 5/5\n",
    "\n",
    "### Demo for Task from R. Shwartz-Ziv and N. Tishby (2017, arXiv https://arxiv.org/abs/1703.00810)\n",
    "### (Toy dataset with 12 bits input and binary decision task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "cm = 1/2.54  # centimeters to inches\n",
    "\n",
    "import nninfo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set experiment id\n",
    "experiment_id = \"tishby_demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before rerunning the experiment, remove the previous version\n",
    "import nninfo.utils\n",
    "nninfo.utils.remove_experiment(experiment_id, silent=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up parameters and train first network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we do not set initial seeds manually here, but save all seeds to the\n",
    "# checkpoints files during training for later reproducibility. Rerunning this script\n",
    "# will produce slightly different figures due to the randomness of network\n",
    "# initialization etc.\n",
    "\n",
    "layer_infos = [\n",
    "    nninfo.LayerInfo(connection_layer='input', activation_function='input'),\n",
    "    nninfo.LayerInfo(connection_layer='linear', connection_layer_kwargs={'in_features': 784, 'out_features': 12}, activation_function='tanh'),\n",
    "    nninfo.LayerInfo(connection_layer='linear', connection_layer_kwargs={'in_features': 12, 'out_features': 4}, activation_function='tanh'),\n",
    "    nninfo.LayerInfo(connection_layer='linear', connection_layer_kwargs={'in_features': 4, 'out_features': 4}, activation_function='tanh'),\n",
    "    nninfo.LayerInfo(connection_layer='linear', connection_layer_kwargs={'in_features': 4, 'out_features': 4}, activation_function='tanh'),\n",
    "    nninfo.LayerInfo(connection_layer='linear', connection_layer_kwargs={'in_features': 4, 'out_features': 1}, activation_function='sigmoid')\n",
    "]\n",
    "\n",
    "initializer_name = 'xavier'\n",
    "\n",
    "# Create network instance\n",
    "network = nninfo.NeuralNetwork(layer_infos=layer_infos, init_str=initializer_name)\n",
    "\n",
    "# Set task instance\n",
    "task = nninfo.TaskManager('tishby_dat')\n",
    "\n",
    "# Split dataset into Shwartz-Ziv and Tishby training set, and test set\n",
    "task['full_set'].train_test_val_random_split(2796, 1300, 0, seed=42)\n",
    "print(task)\n",
    "\n",
    "# Create quantizer list with stochastic quantization. The input layer is not quantized.\n",
    "quantizer = [None] + 4 * [{'levels': 8, 'rounding_point': 'stochastic'}] + [None]\n",
    "\n",
    "# Initialize training components\n",
    "trainer = nninfo.Trainer(dataset_name='full_set/train',\n",
    "                                optim_str='SGD',\n",
    "                                loss_str='BCELoss',\n",
    "                                lr=0.01,\n",
    "                                shuffle=True,\n",
    "                                batch_size=64,\n",
    "                                quantizer=quantizer)\n",
    "\n",
    "tester = nninfo.Tester(dataset_name='full_set/test')\n",
    "\n",
    "# Save training state for 30 logarithmically spaced checkpoints\n",
    "schedule = nninfo.Schedule()\n",
    "schedule.create_log_spaced_chapters(1000, 30)\n",
    "\n",
    "# Set up experiment\n",
    "exp = nninfo.Experiment(experiment_id, network, task, trainer, tester, schedule)\n",
    "\n",
    "# Run training for 1000 epochs\n",
    "exp.run_following_schedule(compute_test_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up experiment\n",
    "exp = nninfo.Experiment.load(experiment_id)\n",
    "\n",
    "# Compute 9 more training runs with different random weight initializations.\n",
    "exp.rerun(9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate network performance\n",
    "#### Compute loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute loss and accuracy\n",
    "\n",
    "quantizer_params = [None] + 4 * [{'levels': 8, 'rounding_point': 'center_saturating'}] + [None]\n",
    "\n",
    "experiment = nninfo.Experiment.load(experiment_id)\n",
    "perf_measurement = nninfo.analysis.PerformanceMeasurement(experiment, ['full_set/train', 'full_set/test'], quantizer_params=quantizer_params)\n",
    "\n",
    "perf_measurement.perform_measurements(run_ids='all', chapter_ids='all', exists_ok=True)\n",
    "perf_measurement.results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load performance file\n",
    "experiment = nninfo.Experiment.load(experiment_id)\n",
    "performance_measurement = nninfo.analysis.PerformanceMeasurement.load(experiment, \"performance\")\n",
    "performance_results = performance_measurement.results\n",
    "\n",
    "cm = 1/2.54\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4*cm, 4*cm), dpi=150)\n",
    "twinax = ax.twinx()\n",
    "\n",
    "# Plot accuracy\n",
    "nninfo.plot.plot_loss_accuracy(performance_results, ax, twinax)\n",
    "\n",
    "ax.legend(ncol=1, bbox_to_anchor=(1.5, 0.5), loc='center left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result\n",
    "plt.savefig(f\"experiments/exp_{experiment_id}/plots/performance.pdf\", bbox_inches='tight');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform quadravariate PID on hidden layers $L_3$, $L_4$ and $L_5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nninfo.model.neural_network import NeuronID\n",
    "\n",
    "# Load experiment\n",
    "exp = nninfo.experiment.Experiment.load(experiment_id)\n",
    "\n",
    "for layer in [2, 3, 4]:\n",
    "\n",
    "    target = [NeuronID('Y', (1,))]\n",
    "    source1 = [NeuronID(f'L{layer}', (1,))]\n",
    "    source2 = [NeuronID(f'L{layer}', (2,))]\n",
    "    source3 = [NeuronID(f'L{layer}', (3,))]\n",
    "    source4 = [NeuronID(f'L{layer}', (4,))]\n",
    "\n",
    "    # Create quantizer list for deterministic rounding.\n",
    "    quantization_dict = [None] + 6 * [{'levels': 8, 'rounding_point': 'center_saturating'}]\n",
    "\n",
    "    # Set up analysis environment\n",
    "    measurement = nninfo.analysis.pid_measurement.PIDMeasurement(experiment=exp,\n",
    "                                                     measurement_id=f'pid_L{layer}',\n",
    "                                                     dataset_name='full_set/train',\n",
    "                                                     quantizer_params=quantization_dict,\n",
    "\n",
    "                                                     pid_definition='reing',\n",
    "                                                     binning_kwargs={'binning_method' : 'none'},\n",
    "                                                     target_id_list=target,\n",
    "                                                     source_id_lists=[source1, source2, source3, source4])\n",
    "\n",
    "    itic = time.time_ns()\n",
    "\n",
    "    # Compute PID for all chapters of all random network initializations\n",
    "    measurement.perform_measurements(run_ids=[0], chapter_ids='all')\n",
    "\n",
    "    itoc = time.time_ns()\n",
    "    print(f\"Computing PID for L{layer} took: \", (itoc-itic)/10**9, \"s\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute representational complexity and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "from nninfo.postprocessing.pid_postprocessing import get_pid_summary_quantities\n",
    "\n",
    "fig, ax= plt.subplots(figsize=(5*cm, 4*cm), dpi=150)\n",
    "inset_axis = inset_axes(ax, width=0.7, height=0.4)\n",
    "\n",
    "# Load experiment\n",
    "experiment = nninfo.experiment.Experiment.load(experiment_id)\n",
    "\n",
    "# Plot accuracy on inset axis\n",
    "performance_measurement = nninfo.analysis.PerformanceMeasurement.load(experiment, 'performance')\n",
    "nninfo.plot.plot_accuracy(performance_measurement.results, 'full_set/train', inset_axis, c='k', label='Train')\n",
    "nninfo.plot.plot_accuracy(performance_measurement.results, 'full_set/test', inset_axis, c='k', ls='--', label='Test')\n",
    "inset_axis.set_ylim(0, 1)\n",
    "inset_axis.set_ylabel('Acc.')\n",
    "inset_axis.legend(bbox_to_anchor=(1.1, 1.3), loc='upper left')\n",
    "    \n",
    "for layer in [2, 3, 4]:\n",
    "    measurement_loaded = nninfo.analysis.PIDMeasurement.load(experiment=experiment, measurement_id=f'pid_L{layer}')\n",
    "    pid_summary = get_pid_summary_quantities(measurement_loaded.results)\n",
    "    nninfo.plot.plot_representational_complexity(pid_summary, ax, label=f'Layer {layer}')\n",
    "\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.25))\n",
    "\n",
    "ax.set_xlabel('Training Epoch')\n",
    "ax.set_ylabel(r'Repr. Compl. $C$')\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1, .6), loc='upper left')\n",
    "\n",
    "ax.set_ylim(1, 4)\n",
    "ax.set_yticks([1, 2, 3])\n",
    "ax.set_yticklabels(['1', '2', '3']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nninfo.postprocessing.pid_postprocessing import get_pid_summary_quantities\n",
    "\n",
    "for layer in [2, 3, 4]:\n",
    "    fig, ax= plt.subplots(figsize=(5*cm, 4*cm), sharex=True, dpi=150)\n",
    "    experiment = nninfo.experiment.Experiment.load(experiment_id)\n",
    "\n",
    "    measurement_loaded = nninfo.analysis.PIDMeasurement.load(experiment=experiment, measurement_id=f'pid_L{layer}')\n",
    "    pid_summary = get_pid_summary_quantities(measurement_loaded.results)\n",
    "    nninfo.plot.plot_degree_of_synergy_atoms(pid_summary, ax)\n",
    "\n",
    "    ax.set_xlabel('Training Epoch')\n",
    "    ax.set_ylabel(r'Deg. of Syn. atoms (bits)')\n",
    "\n",
    "    ax.set_title(f'Layer {layer}')\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "plt.savefig(f\"experiments/exp_{experiment_id}/plots/representational_complexity.pdf\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('nninfo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "eb676ebef6b5cf8ce51c716d153b38a6d674dadf41aeaecb86761f2bdfa1f1da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
